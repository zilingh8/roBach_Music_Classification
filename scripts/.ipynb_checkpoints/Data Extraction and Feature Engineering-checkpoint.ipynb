{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from music21 import *\n",
    "from IPython.display import Audio\n",
    "from intervaltree import Interval,IntervalTree\n",
    "from collections import Counter\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is 21 gigabytes and is too large to upload to github. We uploaded it to google drive and  mounted the data on a Google Collab notebook in order to extract the data features. \n",
    "\n",
    "- The raw file location references the google drive file locations. \n",
    "\n",
    "- Once the run was complete, the extracted features were then exported to csv files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all train label csvs into pandas and concatenate into one dataframe\n",
    "\n",
    "#Use glob to get all the csv files in the test folder\n",
    "\n",
    "train_path = '/content/drive/My Drive/w207_dataset/train_labels'\n",
    "\n",
    "#Use os.path.join as this makes concatenation OS independent\n",
    "all_train_labels = glob.glob(os.path.join(train_path, \"*.csv\"))     \n",
    "\n",
    "df_from_each_train_file = (pd.read_csv(f).assign(file_name=os.path.basename(f).split('.')[0]) for f in all_train_labels)\n",
    "\n",
    "df_train_labels   = pd.concat(df_from_each_train_file, ignore_index=True)\n",
    "\n",
    "#Save it as a csv\n",
    "df_train_labels.to_csv('/content/drive/My Drive/w207_dataset/df_train_labels_consol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first 5 rows of data\n",
    "\n",
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all test label csvs into pandas and concatenate into one dataframe\n",
    "  \n",
    "# use glob to get all the csv files in the test folder\n",
    "\n",
    "test_path = '/content/drive/My Drive/w207_dataset/test_labels'\n",
    "\n",
    "# use os.path.join as this makes concatenation OS independent\n",
    "all_test_labels = glob.glob(os.path.join(test_path, \"*.csv\"))     \n",
    "\n",
    "df_from_each_test_file = (pd.read_csv(f).assign(file_name=os.path.basename(f).split('.')[0]) for f in all_test_labels)\n",
    "\n",
    "df_test_labels   = pd.concat(df_from_each_test_file, ignore_index=True)\n",
    "\n",
    "#Save it as a csv\n",
    "df_test_labels.to_csv('/content/drive/My Drive/w207_dataset/df_test_labels_consol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 5 rows of data\n",
    "df_test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Spectral Features from Training Wav Data and Save to csv. \n",
    "#### The extraction was done in three parts for the training set due to the size and this process took 6 hours due to file size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief Summary of the features being extracted:\n",
    "- Harmonic or Percussive Instrument : Harmonic sound is perceived as pitched sounds while Percussive sound is consonant like e.g. drums\n",
    "\n",
    "-   Mel-Frequency Cepstral Coefficients  : Representation of the short-term power spectrum of a sound\n",
    "\n",
    "- Chroma Features : Tonal content of a musical audio signal in a condensed form\n",
    "\n",
    "-  Spectral Contrast : The level difference between peaks and valleys in the sound spectrum.\n",
    "\n",
    "-  Mel-Scaled Spectogram  : Represents signal loudness as it varies over time at different frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(file):\n",
    "#function to extract features in Wav files with librosa\n",
    "\n",
    "    \n",
    "    #wave representation\n",
    "    y, sr = librosa.load(file)\n",
    "        \n",
    "    #determine if instrument is harmonic or percussive \n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    if np.mean(y_harmonic)>np.mean(y_percussive):\n",
    "        harmonic=1\n",
    "    else:\n",
    "        harmonic=0\n",
    "        \n",
    "    #Mel-frequency cepstral coefficients\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    #averaging mfcc over time\n",
    "    mfcc=np.mean(mfcc,axis=1)\n",
    "    \n",
    "    #get the mel-scaled spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)  \n",
    "    #average spectrogram over time\n",
    "    spectrogram = np.mean(spectrogram, axis = 1)\n",
    "    \n",
    "    #get chroma energy\n",
    "    chroma = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    #average chroma over time\n",
    "    chroma = np.mean(chroma, axis = 1)\n",
    "    \n",
    "    #spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    contrast = np.mean(contrast, axis= 1)\n",
    "    \n",
    "    return [harmonic, mfcc, spectrogram, chroma, contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav_path = '/content/drive/My Drive/w207_dataset/train_data'\n",
    "  \n",
    "# use os.path.join as this makes concatenation OS independent\n",
    "all_train_wav = glob.glob(os.path.join(train_wav_path, \"*.wav\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract training data in in 3 parts, part 1 : first 100\n",
    "df_train_wav1 = pd.DataFrame(columns=[\"harmonic\", \"mfcc\", \"spectrogram\", \"chroma\", \"contrast\",\"filename\"])\n",
    "for filename in all_train_wav[0:100]:\n",
    "  a = feature_extract(filename)\n",
    "  a.append(os.path.basename(filename).split('.')[0])\n",
    "  df_train_wav1.loc[len(df_train_wav1)]= a\n",
    "\n",
    "\n",
    "#extract mfccs\n",
    "mfcc_train1 = pd.DataFrame(df_train_wav1.mfcc.values.tolist(),index=df_train_wav1.index)\n",
    "mfcc_train1 = mfcc_train1.add_prefix('mfcc_')\n",
    "\n",
    "#extract spectro\n",
    "spectro_train1 = pd.DataFrame(df_train_wav1.spectrogram.values.tolist(),index=df_train_wav1.index)\n",
    "spectro_train1 = spectro_train1.add_prefix('spectro_')\n",
    "\n",
    "#extract chroma\n",
    "chroma_train1 = pd.DataFrame(df_train_wav1.chroma.values.tolist(),index=df_train_wav1.index)\n",
    "chroma_train1 = chroma_train1.add_prefix('chroma_')\n",
    "\n",
    "#extract contrast\n",
    "contrast_train1 = pd.DataFrame(df_train_wav1.contrast.values.tolist(),index=df_train_wav1.index)\n",
    "contrast_train1 = chroma_train1.add_prefix('contrast_')\n",
    "\n",
    "#drop the old columns\n",
    "df_train_wav1 = df_train_wav1.drop(labels=['mfcc', 'spectrogram', 'chroma', 'contrast'], axis=1)\n",
    "\n",
    "#concatenate\n",
    "df_train_wav_fin1=pd.concat([df_train_wav1, mfcc_train1, spectro_train1, chroma_train1, contrast_train1],\n",
    "                           axis=1, join='inner')\n",
    "df_train_wav_fin1.head()\n",
    "\n",
    "#Save to csv\n",
    "df_train_wav_fin1.to_csv('/content/drive/My Drive/w207_dataset/df_train_wav_finc1.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Extract training data in in 3 parts, part 2 : second 100\n",
    "df_train_wav2 = pd.DataFrame(columns=[\"harmonic\", \"mfcc\", \"spectrogram\", \"chroma\", \"contrast\",\"filename\"])\n",
    "for filename in all_train_wav[100:200]:\n",
    "  a = feature_extract(filename)\n",
    "  a.append(os.path.basename(filename).split('.')[0])\n",
    "  df_train_wav2.loc[len(df_train_wav2)]= a\n",
    "\n",
    "\n",
    "#extract mfccs\n",
    "mfcc_train2 = pd.DataFrame(df_train_wav2.mfcc.values.tolist(),index=df_train_wav2.index)\n",
    "mfcc_train2 = mfcc_train2.add_prefix('mfcc_')\n",
    "\n",
    "#extract spectro\n",
    "spectro_train2 = pd.DataFrame(df_train_wav2.spectrogram.values.tolist(),index=df_train_wav2.index)\n",
    "spectro_train2 = spectro_train2.add_prefix('spectro_')\n",
    "\n",
    "#extract chroma\n",
    "chroma_train2 = pd.DataFrame(df_train_wav2.chroma.values.tolist(),index=df_train_wav2.index)\n",
    "chroma_train2 = chroma_train2.add_prefix('chroma_')\n",
    "\n",
    "#extract contrast\n",
    "contrast_train2 = pd.DataFrame(df_train_wav2.contrast.values.tolist(),index=df_train_wav2.index)\n",
    "contrast_train2 = chroma_train2.add_prefix('contrast_')\n",
    "\n",
    "#drop the old columns\n",
    "df_train_wav2 = df_train_wav2.drop(labels=['mfcc', 'spectrogram', 'chroma', 'contrast'], axis=1)\n",
    "\n",
    "#concatenate\n",
    "df_train_wav_fin2=pd.concat([df_train_wav2, mfcc_train2, spectro_train2, chroma_train2, contrast_train2],\n",
    "                           axis=1, join='inner')\n",
    "df_train_wav_fin2.head()\n",
    "\n",
    "#Save to csv\n",
    "df_train_wav_fin2.to_csv('/content/drive/My Drive/w207_dataset/df_train_wav_finc2.csv')\n",
    "\n",
    "#Extract training data in in 3 parts, part 3 : last 120\n",
    "df_train_wav3 = pd.DataFrame(columns=[\"harmonic\", \"mfcc\", \"spectrogram\", \"chroma\", \"contrast\",\"filename\"])\n",
    "for filename in all_train_wav[200:320]:\n",
    "  a = feature_extract(filename)\n",
    "  a.append(os.path.basename(filename).split('.')[0])\n",
    "  df_train_wav3.loc[len(df_train_wav3)]= a\n",
    "\n",
    "#extract mfccs\n",
    "mfcc_train3 = pd.DataFrame(df_train_wav3.mfcc.values.tolist(),index=df_train_wav3.index)\n",
    "mfcc_train3 = mfcc_train3.add_prefix('mfcc_')\n",
    "\n",
    "#extract spectro\n",
    "spectro_train3 = pd.DataFrame(df_train_wav3.spectrogram.values.tolist(),index=df_train_wav3.index)\n",
    "spectro_train3 = spectro_train3.add_prefix('spectro_')\n",
    "\n",
    "#extract chroma\n",
    "chroma_train3 = pd.DataFrame(df_train_wav3.chroma.values.tolist(),index=df_train_wav3.index)\n",
    "chroma_train3 = chroma_train3.add_prefix('chroma_')\n",
    "\n",
    "#extract contrast\n",
    "contrast_train3 = pd.DataFrame(df_train_wav3.contrast.values.tolist(),index=df_train_wav3.index)\n",
    "contrast_train3 = chroma_train3.add_prefix('contrast_')\n",
    "\n",
    "#drop the old columns\n",
    "df_train_wav3 = df_train_wav3.drop(labels=['mfcc', 'spectrogram', 'chroma', 'contrast'], axis=1)\n",
    "\n",
    "#concatenate\n",
    "df_train_wav_fin3=pd.concat([df_train_wav3, mfcc_train3, spectro_train3, chroma_train3, contrast_train3],\n",
    "                           axis=1, join='inner')\n",
    "\n",
    "df_train_wav_fin3.head()\n",
    "\n",
    "df_train_wav_fin3.to_csv('/content/drive/My Drive/w207_dataset/df_train_wav_finc3.csv')\n",
    "\n",
    "#Concatenate the three training sample dfs and save to a consolidated csv\n",
    "train_frames = [df_train_wav_fin1,df_train_wav_fin2,df_train_wav_fin3]\n",
    "df_train_wav_consol = pd.concat(train_frames , ignore_index=True)\n",
    "df_train_wav_consol.to_csv('/content/drive/My Drive/w207_dataset/df_train_wav_consolidated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Spectral Features from Test Wav File Data and Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav_path = '/content/drive/My Drive/w207_dataset/test_data'\n",
    "\n",
    "# use os.path.join as this makes concatenation OS independent\n",
    "all_test_wav = glob.glob(os.path.join(test_wav_path, \"*.wav\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe for Test Wav data , Extract File Names\n",
    "df_test_wav = pd.DataFrame(columns=[\"harmonic\", \"mfcc\", \"spectrogram\", \"chroma\", \"contrast\",\"filename\"])\n",
    "for filename in all_test_wav:\n",
    "  a = feature_extract(filename)\n",
    "  a.append(os.path.basename(filename).split('.')[0])\n",
    "  df_test_wav.loc[len(df_test_wav)]= a\n",
    "\n",
    "#extract mfccs\n",
    "mfcc_test = pd.DataFrame(df_test_wav.mfcc.values.tolist(),index=df_test_wav.index)\n",
    "mfcc_test = mfcc_test.add_prefix('mfcc_')\n",
    "\n",
    "#extract spectro\n",
    "spectro_test = pd.DataFrame(df_test_wav.spectrogram.values.tolist(),index=df_test_wav.index)\n",
    "spectro_test = spectro_test.add_prefix('spectro_')\n",
    "\n",
    "#extract chroma\n",
    "chroma_test = pd.DataFrame(df_test_wav.chroma.values.tolist(),index=df_test_wav.index)\n",
    "chroma_test = chroma_test.add_prefix('chroma_')\n",
    "\n",
    "\n",
    "#extract contrast\n",
    "contrast_test = pd.DataFrame(df_test_wav.contrast.values.tolist(),index=df_test_wav.index)\n",
    "contrast_test = chroma_test.add_prefix('contrast_')\n",
    "\n",
    "#drop the old columns\n",
    "df_test_wav = df_test_wav.drop(labels=['mfcc', 'spectrogram', 'chroma', 'contrast'], axis=1)\n",
    "\n",
    "#concatenate\n",
    "df_test_wav_fin=pd.concat([df_test_wav, mfcc_test, spectro_test, chroma_test, contrast_test],\n",
    "                           axis=1, join='inner')\n",
    "df_test_wav_fin.head()\n",
    "\n",
    "#Save to csv\n",
    "df_test_wav_fin.to_csv('/content/drive/My Drive/w207_dataset/df_test_wav_finc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section of the notebook, we committed the exported csvs to github and file locations referenced are for csvs in github.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv features which were extracted from earlier Data PreProcessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "\n",
    "#Get metadata\n",
    "metadata=pd.read_csv('../data/musicnet_metadata.csv')\n",
    "\n",
    "# Get consolidated saved csvs of WAV Spectral features only\n",
    "train_wav = pd.read_csv('../data/df_train_wav_consolidated.csv',index_col=0)\n",
    "test_wav = pd.read_csv('../data/df_test_wav_finc.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Wav Data for Spectral Features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhuang\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4908: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#Create X and y for Wav Data only\n",
    "\n",
    "#Make a copy of the metadata\n",
    "meta_data_copy = metadata.copy(deep=True)\n",
    "meta_data_copy.reset_index(inplace=True)\n",
    "\n",
    "#Rename column name\n",
    "meta_data_copy = meta_data_copy.rename(columns = {'id':'filename'})\n",
    "\n",
    "#Merge Metadata and Wav Data Only\n",
    "merged_train_data_w = pd.merge(train_wav , meta_data_copy , on=\"filename\")\n",
    "merged_train_data_w = merged_train_data_w.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "merged_test_data_w = pd.merge(test_wav , meta_data_copy , on=\"filename\")\n",
    "merged_test_data_w = merged_test_data_w.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "#Checked that unique ensembles in test are a subset of train\n",
    "#Get list of unique ensembles\n",
    "ens_list = merged_train_data_w['ensemble'].unique()\n",
    "\n",
    "#Map list of unique ensemble names to integer\n",
    "mapping = {item:i for i, item in enumerate(ens_list)}\n",
    "merged_train_data_w[\"ensemble\"] = merged_train_data_w[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "merged_test_data_w[\"ensemble\"] = merged_test_data_w[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#This is the original train test split given in kaggle. \n",
    "#The code is selecting only the ensemble for the y and letting the rest of the features be in X\n",
    "\n",
    "X_original_train = merged_train_data_w.iloc[:,np.r_[:167,168]]\n",
    "X_original_test = merged_test_data_w.iloc[:,np.r_[:167,168]]\n",
    "\n",
    "y_original_train = merged_train_data_w.iloc[:,167:168]\n",
    "y_original_test = merged_test_data_w.iloc[:,167:168]\n",
    "\n",
    "#Concatenate the training and test data\n",
    "x_frames = [X_original_train,X_original_test]\n",
    "X_wav = pd.concat(x_frames , ignore_index=True)\n",
    "\n",
    "y_frames = [y_original_train,y_original_test]\n",
    "y_wav = pd.concat(y_frames , ignore_index=True)\n",
    "\n",
    "#Find the index position of viola quintet and drop it since there is only one ensemble of that type\n",
    "index_violaquintet_wav_only = y_wav[ y_wav['ensemble'] == 3 ].index\n",
    "y_wav.drop(index_violaquintet_wav_only , inplace=True)\n",
    "X_wav.drop(index_violaquintet_wav_only , inplace=True)\n",
    "\n",
    "#This is the train test split for Spectral Wav Data only\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_wav, y_wav, train_size=0.80, test_size=0.20, stratify=y_wav, random_state=101)\n",
    "\n",
    "#Get list of file names in train and test to apply split consistently on other datasets\n",
    "filenames_in_train = list(X_train_w['filename'])\n",
    "filenames_in_test = list(X_test_w['filename'])\n",
    "\n",
    "#Remove File name from features\n",
    "X_train_w.drop('filename',axis=1,inplace=True) \n",
    "X_test_w.drop('filename',axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print list of ensembles for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Piano Quintet', 'Solo Piano', 'Piano Trio', 'Viola Quintet',\n",
       "       'String Quartet', 'Clarinet Quintet',\n",
       "       'Pairs Clarinet-Horn-Bassoon', 'Wind Quintet', 'Accompanied Cello',\n",
       "       'Accompanied Clarinet', 'Wind and Strings Octet', 'String Sextet',\n",
       "       'Piano Quartet', 'Horn Piano Trio', 'Solo Violin', 'Solo Flute',\n",
       "       'Solo Cello', 'Violin and Harpsichord',\n",
       "       'Clarinet-Cello-Piano Trio', 'Accompanied Violin', 'Wind Octet'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print ensemble list\n",
    "ens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MIDI Features for Engineered Features from Granular Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import consolidated saved csvs of wav features\n",
    "\n",
    "train_wav = pd.read_csv('../data/df_train_wav_consolidated.csv',index_col=0)\n",
    "test_wav = pd.read_csv('../data/df_test_wav_finc.csv',index_col=0)\n",
    "\n",
    "#Get metadata\n",
    "metadata=pd.read_csv('../data/musicnet_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the metadata\n",
    "meta_data_copy = metadata.copy(deep=True)\n",
    "meta_data_copy.reset_index(inplace=True)\n",
    "#Rename column name\n",
    "meta_data_copy = meta_data_copy.rename(columns = {'id':'filename'})\n",
    "\n",
    "merged_train_data = pd.merge(train_wav , meta_data_copy , on=\"filename\")\n",
    "merged_train_data = merged_train_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "merged_test_data = pd.merge(test_wav , meta_data_copy , on=\"filename\")\n",
    "merged_test_data = merged_test_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering by calculating derived features from granular MIDI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import midi file tables\n",
    "train_labels = pd.read_csv('../data/df_train_labels_consol.csv')\n",
    "test_labels = pd.read_csv('../data/df_test_labels_consol.csv')\n",
    "\n",
    "#combine train and test data\n",
    "labels_frames = [train_labels,test_labels]\n",
    "labels = pd.concat(labels_frames , ignore_index=True)\n",
    "\n",
    "#create series with various midi features\n",
    "\n",
    "#number of unique instruments\n",
    "midi_nunique_inst = labels.groupby('file_name').agg({\"instrument\": \"nunique\"}).reset_index().rename(columns={\"instrument\": \"midi_nunique_inst\"})\n",
    "\n",
    "#number of unique notes\n",
    "midi_nunique_note = labels.groupby('file_name').agg({\"note\": \"nunique\"}).reset_index().rename(columns={\"note\": \"midi_nunique_note\"})\n",
    "\n",
    "#total number of notes\n",
    "midi_num_notes = labels.groupby('file_name').sum()[['note']].reset_index().rename(columns={'note':'midi_num_notes'})\n",
    "\n",
    "#quintiles of the distribution of note values (pitches)\n",
    "midi_min_note = labels.groupby('file_name').min()[['note']].reset_index().rename(columns={'note':'midi_min_note'})\n",
    "midi_second_quintile_note = labels[['file_name','note']].groupby('file_name').quantile(q=0.25,interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_second_quintile_note'})\n",
    "midi_median_note = labels[['file_name','note']].groupby('file_name').quantile(interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_median_note'})\n",
    "midi_fourth_quintile_note = labels[['file_name','note']].groupby('file_name').quantile(q=0.75,interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_fourth_quintile_note'})\n",
    "midi_max_note = labels[['file_name','note']].groupby('file_name').max()[['note']].reset_index().rename(columns={'note':'midi_max_note'})\n",
    "\n",
    "#average number of notes per instrument\n",
    "midi_avg_notes_inst = labels.groupby(['file_name','instrument']).sum()[['note']].groupby('file_name').mean().reset_index().rename(columns={'note':'midi_avg_notes_inst'})\n",
    "\n",
    "#merge all columns together\n",
    "midi_features = midi_nunique_inst.merge(midi_nunique_note, on='file_name')\n",
    "midi_features = midi_features.merge(midi_num_notes,on='file_name')\n",
    "midi_features = midi_features.merge(midi_min_note,on='file_name')\n",
    "midi_features = midi_features.merge(midi_second_quintile_note,on='file_name')\n",
    "midi_features = midi_features.merge(midi_median_note,on='file_name')\n",
    "midi_features = midi_features.merge(midi_fourth_quintile_note,on='file_name')\n",
    "midi_features = midi_features.merge(midi_max_note,on='file_name')\n",
    "midi_features = midi_features.merge(midi_avg_notes_inst,on='file_name')\n",
    "\n",
    "midi_features.to_csv('../data/midi_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get midi features only\n",
    "midi_features = pd.read_csv('../data/midi_features.csv',index_col=0)\n",
    "\n",
    "#Create X and y for Engineered MIDI Data Attributes only\n",
    "\n",
    "#Make a copy of the midi features\n",
    "midi_features_copy = midi_features.copy(deep=True)\n",
    "midi_features_copy.reset_index(inplace=True)\n",
    "\n",
    "#Rename column name in both the copy and the original\n",
    "midi_features_copy = midi_features_copy.rename(columns = {'file_name':'filename'})\n",
    "midi_features = midi_features.rename(columns = {'file_name':'filename'})\n",
    "\n",
    "\n",
    "#Merge Metadata and MIDI Data only\n",
    "\n",
    "#For original midi\n",
    "merged_midi_data = pd.merge(midi_features , meta_data_copy , on=\"filename\")\n",
    "merged_midi_data = merged_midi_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "#For midi copy\n",
    "merged_midi_data_copy = pd.merge(midi_features_copy , meta_data_copy , on=\"filename\")\n",
    "merged_midi_data_copy = merged_midi_data_copy.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index_x\"], axis=1)\n",
    "\n",
    "#Map list of unique ensemble names to integer\n",
    "\n",
    "#For original midi\n",
    "merged_midi_data[\"ensemble\"] = merged_midi_data[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#For midi copy\n",
    "merged_midi_data_copy[\"ensemble\"] = merged_midi_data_copy[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#To select data for train and test for midi based on the same splits done for wav based on multiple conditions you can use &:\n",
    "#Removes file name as a feature and also removes viola quintet\n",
    "midi_train = merged_midi_data.loc[merged_midi_data['filename'].isin(filenames_in_train)]\n",
    "X_train_m = midi_train.iloc[:,np.r_[1:10,11]]\n",
    "y_train_m = midi_train.iloc[:,np.r_[10]]\n",
    "\n",
    "midi_test = merged_midi_data.loc[merged_midi_data['filename'].isin(filenames_in_test)]\n",
    "X_test_m = midi_test.iloc[:,np.r_[1:10,11]]\n",
    "y_test_m = midi_test.iloc[:,np.r_[10]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Merged Dataset comprising Engineered Features from MIDI Data and Spectral Features from Wav Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset with MIDI and WAV Spectral Data\n",
    "\n",
    "#Drop duplicate columns\n",
    "merged_midi_data_copy.drop(['seconds','index_y'],axis=1,inplace=True) \n",
    "\n",
    "#Find the index position of viola quintet and drop it since there is only one ensemble of that type\n",
    "index_violaquintet_midi_only = merged_midi_data_copy[ merged_midi_data_copy['ensemble'] == 3 ].index\n",
    "merged_midi_data_copy.drop(index_violaquintet_midi_only , inplace=True)\n",
    "\n",
    "#Merge Midi and Wav Data \n",
    "merged_data_c = pd.merge(X_wav, merged_midi_data_copy , on=\"filename\")\n",
    "\n",
    "#To select data for train and test for midi based on the same splits done for wav based on multiple conditions you can use &:\n",
    "#Removes file name as a feature and also removes viola quintet\n",
    "comb_train = merged_data_c.loc[merged_data_c['filename'].isin(filenames_in_train)]\n",
    "X_train_c = comb_train.iloc[:,np.r_[0,2:177]]\n",
    "y_train_c = comb_train.iloc[:,np.r_[177]]\n",
    "\n",
    "comb_test = merged_data_c.loc[merged_data_c['filename'].isin(filenames_in_test)]\n",
    "X_test_c = comb_test.iloc[:,np.r_[0,2:177]]\n",
    "y_test_c = comb_test.iloc[:,np.r_[177]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Wav Data :\n",
      "(263, 167) (263, 1) (66, 167) (66, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Wav Data :')\n",
    "print( X_train_w.shape, y_train_w.shape , X_test_w.shape , y_test_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MIDI Data :\n",
      "(263, 10) (263, 1) (66, 10) (66, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of MIDI Data :')\n",
    "print( X_train_m.shape, y_train_m.shape , X_test_m.shape , y_test_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Combined Wav and MIDI Data :\n",
      "(263, 176) (263, 1) (66, 176) (66, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Combined Wav and MIDI Data :')\n",
    "print( X_train_c.shape, y_train_c.shape , X_test_c.shape , y_test_c.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
