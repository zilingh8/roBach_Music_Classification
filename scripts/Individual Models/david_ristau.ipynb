{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David.Ristau\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "\n",
    "#Get metadata\n",
    "metadata=pd.read_csv('../data/musicnet_metadata.csv')\n",
    "\n",
    "# Get consolidated saved csvs of WAV Spectral features only\n",
    "train_wav = pd.read_csv('../data/df_train_wav_consolidated.csv',index_col=0)\n",
    "test_wav = pd.read_csv('../data/df_test_wav_finc.csv',index_col=0)\n",
    "\n",
    "#Get midi features only\n",
    "midi_features = pd.read_csv('../data/midi_features.csv',index_col=0)\n",
    "#Create X and y for Wav Data for Spectral Features only\n",
    "\n",
    "#Make a copy of the metadata\n",
    "meta_data_copy = metadata.copy(deep=True)\n",
    "meta_data_copy.reset_index(inplace=True)\n",
    "\n",
    "#Rename column name\n",
    "meta_data_copy = meta_data_copy.rename(columns = {'id':'filename'})\n",
    "\n",
    "#Merge Metadata and Wav Data Only\n",
    "merged_train_data_w = pd.merge(train_wav , meta_data_copy , on=\"filename\")\n",
    "merged_train_data_w = merged_train_data_w.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "merged_test_data_w = pd.merge(test_wav , meta_data_copy , on=\"filename\")\n",
    "merged_test_data_w = merged_test_data_w.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "#Checked that unique ensembles in test are a subset of train\n",
    "#Get list of unique ensembles\n",
    "ens_list = merged_train_data_w['ensemble'].unique()\n",
    "\n",
    "#Map list of unique ensemble names to integer\n",
    "mapping = {item:i for i, item in enumerate(ens_list)}\n",
    "merged_train_data_w[\"ensemble\"] = merged_train_data_w[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "merged_test_data_w[\"ensemble\"] = merged_test_data_w[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#This is the original train test split given in kaggle. \n",
    "#The code is selecting only the ensemble for the y and letting the rest of the features be in X\n",
    "\n",
    "X_original_train = merged_train_data_w.iloc[:,np.r_[:167,168]]\n",
    "X_original_test = merged_test_data_w.iloc[:,np.r_[:167,168]]\n",
    "\n",
    "y_original_train = merged_train_data_w.iloc[:,167:168]\n",
    "y_original_test = merged_test_data_w.iloc[:,167:168]\n",
    "\n",
    "#Concatenate the training and test data\n",
    "x_frames = [X_original_train,X_original_test]\n",
    "X_wav = pd.concat(x_frames , ignore_index=True)\n",
    "\n",
    "y_frames = [y_original_train,y_original_test]\n",
    "y_wav = pd.concat(y_frames , ignore_index=True)\n",
    "\n",
    "#Find the index position of viola quintet and drop it since there is only one ensemble of that type\n",
    "index_violaquintet_wav_only = y_wav[ y_wav['ensemble'] == 3 ].index\n",
    "y_wav.drop(index_violaquintet_wav_only , inplace=True)\n",
    "X_wav.drop(index_violaquintet_wav_only , inplace=True)\n",
    "\n",
    "#This is the train test split for Spectral Wav Data only\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_wav, y_wav, train_size=0.80, test_size=0.20, stratify=y_wav, random_state=101)\n",
    "\n",
    "#Get list of file names in train and test to apply split consistently on other datasets\n",
    "filenames_in_train = list(X_train_w['filename'])\n",
    "filenames_in_test = list(X_test_w['filename'])\n",
    "\n",
    "#Remove File name from features\n",
    "X_train_w.drop('filename',axis=1,inplace=True) \n",
    "X_test_w.drop('filename',axis=1,inplace=True) \n",
    "#Create X and y for Granular MIDI Data Attributes only\n",
    "\n",
    "#Make a copy of the midi features\n",
    "midi_features_copy = midi_features.copy(deep=True)\n",
    "midi_features_copy.reset_index(inplace=True)\n",
    "\n",
    "#Rename column name in both the copy and the original\n",
    "midi_features_copy = midi_features_copy.rename(columns = {'file_name':'filename'})\n",
    "midi_features = midi_features.rename(columns = {'file_name':'filename'})\n",
    "\n",
    "\n",
    "#Merge Metadata and MIDI Data only\n",
    "\n",
    "#For original midi\n",
    "merged_midi_data = pd.merge(midi_features , meta_data_copy , on=\"filename\")\n",
    "merged_midi_data = merged_midi_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "#For midi copy\n",
    "merged_midi_data_copy = pd.merge(midi_features_copy , meta_data_copy , on=\"filename\")\n",
    "merged_midi_data_copy = merged_midi_data_copy.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index_x\"], axis=1)\n",
    "\n",
    "#Map list of unique ensemble names to integer\n",
    "\n",
    "#For original midi\n",
    "merged_midi_data[\"ensemble\"] = merged_midi_data[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#For midi copy\n",
    "merged_midi_data_copy[\"ensemble\"] = merged_midi_data_copy[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "#To select data for train and test for midi based on the same splits done for wav based on multiple conditions you can use &:\n",
    "#Removes file name as a feature and also removes viola quintet\n",
    "midi_train = merged_midi_data.loc[merged_midi_data['filename'].isin(filenames_in_train)]\n",
    "X_train_m = midi_train.iloc[:,np.r_[1:10,11]]\n",
    "y_train_m = midi_train.iloc[:,np.r_[10]]\n",
    "\n",
    "midi_test = merged_midi_data.loc[merged_midi_data['filename'].isin(filenames_in_test)]\n",
    "X_test_m = midi_test.iloc[:,np.r_[1:10,11]]\n",
    "y_test_m = midi_test.iloc[:,np.r_[10]]\n",
    "\n",
    "# Create Dataset with MIDI and WAV Spectral Data\n",
    "\n",
    "#Drop duplicate columns\n",
    "merged_midi_data_copy.drop(['seconds','index_y'],axis=1,inplace=True) \n",
    "\n",
    "#Find the index position of viola quintet and drop it since there is only one ensemble of that type\n",
    "index_violaquintet_midi_only = merged_midi_data_copy[ merged_midi_data_copy['ensemble'] == 3 ].index\n",
    "merged_midi_data_copy.drop(index_violaquintet_midi_only , inplace=True)\n",
    "\n",
    "#Merge Midi and Wav Data \n",
    "merged_data_c = pd.merge(X_wav, merged_midi_data_copy , on=\"filename\")\n",
    "\n",
    "#To select data for train and test for midi based on the same splits done for wav based on multiple conditions you can use &:\n",
    "#Removes file name as a feature and also removes viola quintet\n",
    "comb_train = merged_data_c.loc[merged_data_c['filename'].isin(filenames_in_train)]\n",
    "X_train_c = comb_train.iloc[:,np.r_[0,2:177]]\n",
    "y_train_c = comb_train.iloc[:,np.r_[177]]\n",
    "\n",
    "comb_test = merged_data_c.loc[merged_data_c['filename'].isin(filenames_in_test)]\n",
    "X_test_c = comb_test.iloc[:,np.r_[0,2:177]]\n",
    "y_test_c = comb_test.iloc[:,np.r_[177]]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harmonic</th>\n",
       "      <th>mfcc_0</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>...</th>\n",
       "      <th>seconds</th>\n",
       "      <th>midi_nunique_inst</th>\n",
       "      <th>midi_nunique_note</th>\n",
       "      <th>midi_num_notes</th>\n",
       "      <th>midi_min_note</th>\n",
       "      <th>midi_second_quintile_note</th>\n",
       "      <th>midi_median_note</th>\n",
       "      <th>midi_fourth_quintile_note</th>\n",
       "      <th>midi_max_note</th>\n",
       "      <th>midi_avg_notes_inst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-336.124298</td>\n",
       "      <td>151.521805</td>\n",
       "      <td>-6.498520</td>\n",
       "      <td>25.719015</td>\n",
       "      <td>1.903765</td>\n",
       "      <td>-5.264452</td>\n",
       "      <td>-1.326775</td>\n",
       "      <td>-7.777116</td>\n",
       "      <td>-4.485620</td>\n",
       "      <td>...</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>503410</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>102</td>\n",
       "      <td>100682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>-364.077087</td>\n",
       "      <td>179.719788</td>\n",
       "      <td>-1.086006</td>\n",
       "      <td>1.966286</td>\n",
       "      <td>6.703442</td>\n",
       "      <td>-3.811754</td>\n",
       "      <td>-6.823844</td>\n",
       "      <td>-4.261116</td>\n",
       "      <td>-4.859100</td>\n",
       "      <td>...</td>\n",
       "      <td>475</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>277814</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>93</td>\n",
       "      <td>277814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>-420.469543</td>\n",
       "      <td>178.669510</td>\n",
       "      <td>7.665407</td>\n",
       "      <td>-2.792923</td>\n",
       "      <td>8.000317</td>\n",
       "      <td>-3.225939</td>\n",
       "      <td>-6.699994</td>\n",
       "      <td>-6.925910</td>\n",
       "      <td>-5.744388</td>\n",
       "      <td>...</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>103040</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>96</td>\n",
       "      <td>103040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>-256.675049</td>\n",
       "      <td>115.267700</td>\n",
       "      <td>-30.796839</td>\n",
       "      <td>10.840733</td>\n",
       "      <td>-9.554294</td>\n",
       "      <td>-8.928478</td>\n",
       "      <td>-14.532542</td>\n",
       "      <td>-5.173463</td>\n",
       "      <td>-14.122643</td>\n",
       "      <td>...</td>\n",
       "      <td>351</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>324092</td>\n",
       "      <td>36</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>108030.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>-322.953278</td>\n",
       "      <td>108.408386</td>\n",
       "      <td>-5.302370</td>\n",
       "      <td>24.949701</td>\n",
       "      <td>-6.845948</td>\n",
       "      <td>-4.888589</td>\n",
       "      <td>-6.496605</td>\n",
       "      <td>-9.686568</td>\n",
       "      <td>-4.443426</td>\n",
       "      <td>...</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>238414</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>59603.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>-227.172348</td>\n",
       "      <td>133.723526</td>\n",
       "      <td>-28.892586</td>\n",
       "      <td>34.130322</td>\n",
       "      <td>5.551186</td>\n",
       "      <td>-8.405284</td>\n",
       "      <td>-3.688040</td>\n",
       "      <td>-5.177617</td>\n",
       "      <td>-8.855370</td>\n",
       "      <td>...</td>\n",
       "      <td>648</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>406425</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>135475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1</td>\n",
       "      <td>-373.230133</td>\n",
       "      <td>165.598053</td>\n",
       "      <td>5.217481</td>\n",
       "      <td>-4.764515</td>\n",
       "      <td>4.772682</td>\n",
       "      <td>-8.145834</td>\n",
       "      <td>-11.833659</td>\n",
       "      <td>-8.353687</td>\n",
       "      <td>-5.823623</td>\n",
       "      <td>...</td>\n",
       "      <td>445</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>211342</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>93</td>\n",
       "      <td>211342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>-368.525574</td>\n",
       "      <td>169.655411</td>\n",
       "      <td>-0.348883</td>\n",
       "      <td>-4.402245</td>\n",
       "      <td>4.310961</td>\n",
       "      <td>-9.598778</td>\n",
       "      <td>-9.453362</td>\n",
       "      <td>-9.318494</td>\n",
       "      <td>-7.365111</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>47351</td>\n",
       "      <td>38</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>47351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0</td>\n",
       "      <td>-223.069717</td>\n",
       "      <td>129.685623</td>\n",
       "      <td>-39.956688</td>\n",
       "      <td>-0.564331</td>\n",
       "      <td>-29.567814</td>\n",
       "      <td>-22.458815</td>\n",
       "      <td>-18.999100</td>\n",
       "      <td>-19.777555</td>\n",
       "      <td>-20.596846</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>89972</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "      <td>29990.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1</td>\n",
       "      <td>-346.456146</td>\n",
       "      <td>176.933121</td>\n",
       "      <td>-7.661911</td>\n",
       "      <td>-1.755977</td>\n",
       "      <td>3.870136</td>\n",
       "      <td>-5.701828</td>\n",
       "      <td>-10.607601</td>\n",
       "      <td>-9.144874</td>\n",
       "      <td>-6.971035</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>89735</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>95</td>\n",
       "      <td>89735.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     harmonic      mfcc_0      mfcc_1     mfcc_2     mfcc_3     mfcc_4  \\\n",
       "3           0 -336.124298  151.521805  -6.498520  25.719015   1.903765   \n",
       "10          1 -364.077087  179.719788  -1.086006   1.966286   6.703442   \n",
       "24          0 -420.469543  178.669510   7.665407  -2.792923   8.000317   \n",
       "31          1 -256.675049  115.267700 -30.796839  10.840733  -9.554294   \n",
       "37          1 -322.953278  108.408386  -5.302370  24.949701  -6.845948   \n",
       "..        ...         ...         ...        ...        ...        ...   \n",
       "309         1 -227.172348  133.723526 -28.892586  34.130322   5.551186   \n",
       "317         1 -373.230133  165.598053   5.217481  -4.764515   4.772682   \n",
       "325         1 -368.525574  169.655411  -0.348883  -4.402245   4.310961   \n",
       "326         0 -223.069717  129.685623 -39.956688  -0.564331 -29.567814   \n",
       "327         1 -346.456146  176.933121  -7.661911  -1.755977   3.870136   \n",
       "\n",
       "        mfcc_5     mfcc_6     mfcc_7     mfcc_8  ...  seconds  \\\n",
       "3    -5.264452  -1.326775  -7.777116  -4.485620  ...      368   \n",
       "10   -3.811754  -6.823844  -4.261116  -4.859100  ...      475   \n",
       "24   -3.225939  -6.699994  -6.925910  -5.744388  ...      307   \n",
       "31   -8.928478 -14.532542  -5.173463 -14.122643  ...      351   \n",
       "37   -4.888589  -6.496605  -9.686568  -4.443426  ...      466   \n",
       "..         ...        ...        ...        ...  ...      ...   \n",
       "309  -8.405284  -3.688040  -5.177617  -8.855370  ...      648   \n",
       "317  -8.145834 -11.833659  -8.353687  -5.823623  ...      445   \n",
       "325  -9.598778  -9.453362  -9.318494  -7.365111  ...       92   \n",
       "326 -22.458815 -18.999100 -19.777555 -20.596846  ...      139   \n",
       "327  -5.701828 -10.607601  -9.144874  -6.971035  ...      151   \n",
       "\n",
       "     midi_nunique_inst  midi_nunique_note  midi_num_notes  midi_min_note  \\\n",
       "3                    5                 76          503410             26   \n",
       "10                   1                 62          277814             31   \n",
       "24                   1                 48          103040             41   \n",
       "31                   3                 52          324092             36   \n",
       "37                   4                 43          238414             38   \n",
       "..                 ...                ...             ...            ...   \n",
       "309                  3                 61          406425             36   \n",
       "317                  1                 61          211342             28   \n",
       "325                  1                 44           47351             38   \n",
       "326                  3                 35           89972             39   \n",
       "327                  1                 65           89735             28   \n",
       "\n",
       "     midi_second_quintile_note  midi_median_note  midi_fourth_quintile_note  \\\n",
       "3                           56                65                         74   \n",
       "10                          57                64                         72   \n",
       "24                          59                67                         75   \n",
       "31                          59                65                         72   \n",
       "37                          62                68                         74   \n",
       "..                         ...               ...                        ...   \n",
       "309                         57                64                         72   \n",
       "317                         52                59                         71   \n",
       "325                         61                68                         73   \n",
       "326                         58                65                         74   \n",
       "327                         50                64                         74   \n",
       "\n",
       "     midi_max_note  midi_avg_notes_inst  \n",
       "3              102        100682.000000  \n",
       "10              93        277814.000000  \n",
       "24              96        103040.000000  \n",
       "31              89        108030.666667  \n",
       "37              86         59603.500000  \n",
       "..             ...                  ...  \n",
       "309             96        135475.000000  \n",
       "317             93        211342.000000  \n",
       "325             83         47351.000000  \n",
       "326             84         29990.666667  \n",
       "327             95         89735.000000  \n",
       "\n",
       "[66 rows x 176 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_w, X_test_w, y_train_w, y_test_w  spectral features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = '..musicnet/train_data/1727.wav'\n",
    "#y, sr = librosa.load(test_file, sr=None)\n",
    "#y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "#_harmonic.shape\n",
    "#_harmonic = np.array(y_harmonic)\n",
    "#_percussive = np.array(y_percussive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,4))\n",
    "#librosa.display.waveplot(y_harmonic, sr=sr, alpha=0.25)\n",
    "#librosa.display.waveplot(y_percussive, sr=sr, color='r', alpha=0.5)\n",
    "#plt.legend(['Harmonic', 'Percussive'])\n",
    "#plt.title(\"Amplitude Envelope of Harmonic and Percussive Components for \")\n",
    "##plt.savefig('plots/soundsAsArrays_'+str(class_names[i])+'.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to run standard training and testing models with 320 training examples and 10 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav file data, metadata labels\n",
    "#train_data = pd.read_csv('../data/df_train_wav_consolidated.csv')\n",
    "#abels = pd.read_csv('../data/musicnet_metadata.csv')\n",
    "#labels.rename({'id': 'filename'}, axis=1, inplace=True)\n",
    "#train = pd.merge(train_data, labels, on =['filename'])\n",
    "#train.drop(['Unnamed: 0', 'filename', 'composer', 'composition', 'movement', 'source', 'transcriber', 'transcriber', 'catalog_name', 'seconds'], axis=1, inplace=True)  # todo: try to include some of these featues\n",
    "#X_train = train.drop('ensemble', axis=1)\n",
    "#y_train = train['ensemble']\n",
    "#code = {}\n",
    "#j = 0\n",
    "#for i in y_train.value_counts().index:\n",
    "#    code[i] = j\n",
    "#    j+=1\n",
    "#y_train.replace(code, inplace=True)\n",
    "\n",
    "#test_data = pd.read_csv('../data/df_test_wav_finc.csv')\n",
    "#test = pd.merge(test_data, labels, on=['filename'])\n",
    "#test.drop(['Unnamed: 0', 'filename', 'composer', 'composition', 'movement', 'source', 'transcriber', 'transcriber', 'catalog_name', 'seconds'], axis=1, inplace=True)\n",
    "#X_test = test.drop('ensemble', axis=1)\n",
    "#y_test = test['ensemble']\n",
    "#y_test.replace(code, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-69bc9ec4bfc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 0.5, solver='liblinear', multi_class='auto')\n",
    "lr.fit(np.array(X_train), np.array(y_train))\n",
    "predictions = lr.predict(np.array(X_test))\n",
    "print('Accuracy score: ', accuracy_score(predictions, np.array(y_test)))\n",
    "print('F1 Score: ', f1_score(predictions, np.array(y_test), average='weighted'))\n",
    "print('Classification report: \\n', classification_report(y_test, predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, np.array(y_train))\n",
    "predictions = gnb.predict(X_test)\n",
    "print('Accuracy score: ', accuracy_score(predictions, np.array(y_test)))\n",
    "print('F1 Score: ', f1_score(predictions, np.array(y_test), average='weighted'))\n",
    "print('Classification report: \\n', classification_report(y_test, predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "print('Accuracy score: ', accuracy_score(predictions, np.array(y_test)))\n",
    "print('F1 Score: ', f1_score(predictions, np.array(y_test), average='weighted'))\n",
    "print('Classification report: \\n', classification_report(y_test, predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "print('Accuracy score: ', accuracy_score(predictions, np.array(y_test)))\n",
    "print('F1 Score: ', f1_score(predictions, np.array(y_test), average='weighted'))\n",
    "print('Classification report: \\n', classification_report(y_test, predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models run with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to prep data for cross validation X - 330 feature vectors, y - 330 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav file data, metadata labels, all in one dataframe for use with cross validation\n",
    "#train_data = pd.read_csv('csv_data/df_train_wav_consolidated.csv')\n",
    "#labels = pd.read_csv('csv_data/musicnet_metadata.csv')\n",
    "#labels.rename({'id': 'filename'}, axis=1, inplace=True)\n",
    "#train = pd.merge(train_data, labels, on =['filename'])\n",
    "#train.drop(['Unnamed: 0', 'filename', 'composer', 'composition', 'movement', 'source', 'transcriber', 'transcriber', 'catalog_name', 'seconds'], axis=1, inplace=True)  # todo: try to include some of these featues\n",
    "#X_train = train.drop('ensemble', axis=1)\n",
    "#y_train = train['ensemble']\n",
    "#code = {}\n",
    "#j = 0\n",
    "#for i in y_train.value_counts().index:\n",
    "#    code[i] = j\n",
    "#    j+=1\n",
    "#y_train.replace(code, inplace=True)\n",
    "\n",
    "#test_data = pd.read_csv('csv_data/df_test_wav_finc.csv')\n",
    "#test = pd.merge(test_data, labels, on=['filename'])\n",
    "#test.drop(['Unnamed: 0', 'filename', 'composer', 'composition', 'movement', 'source', 'transcriber', 'transcriber', 'catalog_name', 'seconds'], axis=1, inplace=True)\n",
    "#X_test = test.drop('ensemble', axis=1)\n",
    "#y_test = test['ensemble']\n",
    "#y_test.replace(code, inplace=True)\n",
    "\n",
    "#X = pd.concat([X_train, X_test])\n",
    "#y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to run cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE THIS CELL BELOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "CV Scores:  [0.81132075 0.86792453 0.90566038 0.82692308 0.90384615]\n",
      "CV Average and standard deviation:  0.863134978229318 +/- 0.038690476180831046\n",
      "Naive Bayes\n",
      "CV Scores:  [0.71698113 0.75471698 0.73584906 0.75       0.69230769]\n",
      "CV Average and standard deviation:  0.7299709724238026 +/- 0.02295795020311934\n",
      "SVM\n",
      "CV Scores:  [0.62264151 0.64150943 0.66037736 0.65384615 0.67307692]\n",
      "CV Average and standard deviation:  0.6502902757619738 +/- 0.017176625192111616\n",
      "Decision Tree\n",
      "CV Scores:  [0.81132075 0.79245283 0.71698113 0.90384615 0.90384615]\n",
      "CV Average and standard deviation:  0.8256894049346879 +/- 0.07119771260199236\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "# linear regression\n",
    "lr = LogisticRegression(C = 0.5, solver='liblinear', multi_class='auto')\n",
    "scores = cross_val_score(estimator = lr, X=X_train_c, y=y_train_c, cv=5, n_jobs=1)\n",
    "print('Linear regression')\n",
    "print('CV Scores: ', scores)\n",
    "print('CV Average and standard deviation: ', np.mean(scores), '+/-', np.std(scores))\n",
    "# naive bayes\n",
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(estimator = gnb, X=X_train_c, y=y_train_c, cv=5, n_jobs=1)\n",
    "print('Naive Bayes')\n",
    "print('CV Scores: ', scores)\n",
    "print('CV Average and standard deviation: ', np.mean(scores), '+/-', np.std(scores))\n",
    "# SVM\n",
    "svm = SVC()\n",
    "\n",
    "scores = cross_val_score(estimator = svm, X=X_train_c, y=y_train_c, cv=5, n_jobs=1)\n",
    "print('SVM')\n",
    "print('CV Scores: ', scores)\n",
    "print('CV Average and standard deviation: ', np.mean(scores), '+/-', np.std(scores))\n",
    "# decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(estimator = dt, X=X_train_c, y=y_train_c, cv=5, n_jobs=1)\n",
    "print('Decision Tree')\n",
    "print('CV Scores: ', scores)\n",
    "print('CV Average and standard deviation: ', np.mean(scores), '+/-', np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 167)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Midi X_train PCA')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_c = PCA()\n",
    "pca_c.fit_transform(X_train_c)\n",
    "pca_w = PCA()\n",
    "pca_w.fit_transform(X_train_w)\n",
    "pca_m = PCA()\n",
    "pca_m.fit_transform(X_train_m)\n",
    "fig,ax = plt.subplots(3,1,figsize=(15,15))\n",
    "\n",
    "explained_var_list_c = []  # holds explained variance values\n",
    "cumulative_explained_variance_c = []\n",
    "total = 0  # initialize total to 0\n",
    "for i in pca_c.explained_variance_ratio_:  # iterate over explaiend variance ratios\n",
    "    total += i  # sum total variance \n",
    "    cumulative_explained_variance_c.append(total)\n",
    "    \n",
    "explained_var_list_w = []  # holds explained variance values\n",
    "cumulative_explained_variance_w = []\n",
    "total = 0  # initialize total to 0\n",
    "for i in pca_w.explained_variance_ratio_:  # iterate over explaiend variance ratios\n",
    "    total += i  # sum total variance \n",
    "    cumulative_explained_variance_w.append(total) \n",
    "\n",
    "explained_var_list_m = []  # holds explained variance values\n",
    "cumulative_explained_variance_m = []\n",
    "total = 0  # initialize total to 0\n",
    "for i in pca_m.explained_variance_ratio_:  # iterate over explaiend variance ratios\n",
    "    total += i  # sum total variance \n",
    "    cumulative_explained_variance_m.append(total)     \n",
    "    \n",
    "ax[0].bar(x=range(176),\n",
    "        height = pca_c.explained_variance_ratio_,\n",
    "        alpha = 1, align='center', \n",
    "        label='Individual Explained Variance')\n",
    "ax[0].step(x=range(176),\n",
    "       y=cumulative_explained_variance_c,\n",
    "       alpha=0.5,\n",
    "       where='mid',\n",
    "       color='red',\n",
    "       label='Total Explained Variance')\n",
    "ax[0].set_xlabel('Principal Components')\n",
    "ax[0].set_ylabel('Explained variance')\n",
    "ax[0].set_title('Combined X_train PCA')\n",
    "\n",
    "ax[1].bar(x=range(167),\n",
    "        height = pca_w.explained_variance_ratio_,\n",
    "        alpha = 1, align='center', \n",
    "        label='Individual Explained Variance')\n",
    "ax[1].step(x=range(167),\n",
    "       y=cumulative_explained_variance_w,\n",
    "       alpha=0.5,\n",
    "       where='mid',\n",
    "       color='red',\n",
    "       label='Total Explained Variance')\n",
    "ax[1].set_xlabel('Principal Components')\n",
    "ax[1].set_ylabel('Explained variance')\n",
    "ax[1].set_title('Wav X_train PCA')\n",
    "\n",
    "ax[2].bar(x=range(10),\n",
    "        height = pca_m.explained_variance_ratio_,\n",
    "        alpha = 1, align='center', \n",
    "        label='Individual Explained Variance')\n",
    "ax[2].step(x=range(10),\n",
    "       y=cumulative_explained_variance_m,\n",
    "       alpha=0.5,\n",
    "       where='mid',\n",
    "       color='red',\n",
    "       label='Total Explained Variance')\n",
    "ax[2].set_xlabel('Principal Components')\n",
    "ax[2].set_ylabel('Explained variance')\n",
    "ax[2].set_title('Midi X_train PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 176)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2561.7588 - accuracy: 0.3346\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 447.4761 - accuracy: 0.5856\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 302.7360 - accuracy: 0.5019\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 192.1131 - accuracy: 0.6578\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 105.5790 - accuracy: 0.5856\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 173.4297 - accuracy: 0.5475\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 145.0475 - accuracy: 0.5817\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 130.8073 - accuracy: 0.5361\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 124.2507 - accuracy: 0.6502\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 97.6180 - accuracy: 0.5817\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.1623 - accuracy: 0.5970\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.1396 - accuracy: 0.5970\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 100.6173 - accuracy: 0.6654\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.7648 - accuracy: 0.5856\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.7927 - accuracy: 0.6122\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.1779 - accuracy: 0.6008\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 60.9727 - accuracy: 0.5627\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 47.9604 - accuracy: 0.6464\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 45.7721 - accuracy: 0.6958\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 35.7336 - accuracy: 0.6198\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 29.3584 - accuracy: 0.5703\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 20.5052 - accuracy: 0.6578\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 21.2026 - accuracy: 0.5285\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 35.8859 - accuracy: 0.6008\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 45.8206 - accuracy: 0.5285\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 38.1492 - accuracy: 0.6274\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 41.3067 - accuracy: 0.6388\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 37.2165 - accuracy: 0.6654\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 34.5168 - accuracy: 0.6426\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27.5167 - accuracy: 0.5817\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 28.3647 - accuracy: 0.6350\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 25.8890 - accuracy: 0.6122\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 31.7842 - accuracy: 0.5894\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 32.6379 - accuracy: 0.6236\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27.7677 - accuracy: 0.5399\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 30.5555 - accuracy: 0.5399\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 25.5743 - accuracy: 0.6692\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 22.7234 - accuracy: 0.5894\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 33.9552 - accuracy: 0.5361\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27.7406 - accuracy: 0.6350\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 20.8418 - accuracy: 0.6046\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 17.2526 - accuracy: 0.7034\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 17.4806 - accuracy: 0.6122\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 17.2113 - accuracy: 0.6046\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 16.6117 - accuracy: 0.6806\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.4993 - accuracy: 0.5741\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 13.6315 - accuracy: 0.6540\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 11.7312 - accuracy: 0.6578\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4198 - accuracy: 0.6388\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1516 - accuracy: 0.6730\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9926 - accuracy: 0.6806\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.4897 - accuracy: 0.6616\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.8206 - accuracy: 0.6046\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.8108 - accuracy: 0.6996\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.9187 - accuracy: 0.6350\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1870 - accuracy: 0.6768\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.9758 - accuracy: 0.6198\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.6770 - accuracy: 0.6084\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 21.4170 - accuracy: 0.5551\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 13.5745 - accuracy: 0.5551\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10.0897 - accuracy: 0.6920\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.9535 - accuracy: 0.5932\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.5797 - accuracy: 0.6768\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.7278 - accuracy: 0.6198\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8171 - accuracy: 0.6084\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8769 - accuracy: 0.6730\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4190 - accuracy: 0.6236\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.7544 - accuracy: 0.6692\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0046 - accuracy: 0.6350\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2267 - accuracy: 0.7300\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8871 - accuracy: 0.6692\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7747 - accuracy: 0.7072\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4357 - accuracy: 0.6464\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 6.0466 - accuracy: 0.6350\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.7127 - accuracy: 0.6958\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.8105 - accuracy: 0.6426\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.0863 - accuracy: 0.6350\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.8944 - accuracy: 0.6958\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9705 - accuracy: 0.6540\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1440 - accuracy: 0.6882\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3568 - accuracy: 0.6578\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4308 - accuracy: 0.6464\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3089 - accuracy: 0.6426\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0544 - accuracy: 0.6806\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.9513 - accuracy: 0.6654\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4559 - accuracy: 0.7072\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.0670 - accuracy: 0.5551\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.7505 - accuracy: 0.6806\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.8507 - accuracy: 0.6578\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.7808 - accuracy: 0.7034\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.8281 - accuracy: 0.6046\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 6.4146 - accuracy: 0.6160\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.4577 - accuracy: 0.6616\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 6.9126 - accuracy: 0.5399\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.7846 - accuracy: 0.6920\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.6169 - accuracy: 0.6844\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8919 - accuracy: 0.6578\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.3419 - accuracy: 0.5437\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.3131 - accuracy: 0.6616\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.8072 - accuracy: 0.6160\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.8713 - accuracy: 0.6920\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.2995 - accuracy: 0.6464\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.4701 - accuracy: 0.5779\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.5606 - accuracy: 0.6844\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8952 - accuracy: 0.6464\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0541 - accuracy: 0.6768\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.2037 - accuracy: 0.6084\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.3668 - accuracy: 0.6540\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1154 - accuracy: 0.7186\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9101 - accuracy: 0.6692\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7501 - accuracy: 0.6806\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8239 - accuracy: 0.6806\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1346 - accuracy: 0.7262\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6356 - accuracy: 0.6882\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1688 - accuracy: 0.7262\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7409 - accuracy: 0.7414\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1124 - accuracy: 0.6388\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9195 - accuracy: 0.7224\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.8034 - accuracy: 0.7262\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.0064 - accuracy: 0.6806\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6053 - accuracy: 0.6730\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.7233 - accuracy: 0.6996\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.7857 - accuracy: 0.6996\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3700 - accuracy: 0.7567\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.7122 - accuracy: 0.78 - 0s 2ms/step - loss: 2.1103 - accuracy: 0.6806\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6225 - accuracy: 0.6578\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.3301 - accuracy: 0.7643\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3025 - accuracy: 0.7034\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4353 - accuracy: 0.6654\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0554 - accuracy: 0.7262\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6629 - accuracy: 0.7224\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0368 - accuracy: 0.6616\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.1846 - accuracy: 0.6084\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0210 - accuracy: 0.6920\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7864 - accuracy: 0.7338\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2384 - accuracy: 0.6958\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0187 - accuracy: 0.6996\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6140 - accuracy: 0.6958\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5202 - accuracy: 0.7262\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6191 - accuracy: 0.6730\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5257 - accuracy: 0.7148\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3964 - accuracy: 0.6616\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0370 - accuracy: 0.7148\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8532 - accuracy: 0.6844\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8363 - accuracy: 0.7376\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6922 - accuracy: 0.7414\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9404 - accuracy: 0.7072\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6145 - accuracy: 0.7186\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1580 - accuracy: 0.7110\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8291 - accuracy: 0.7186\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2363 - accuracy: 0.6844\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6272 - accuracy: 0.5741\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0642 - accuracy: 0.6768\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.7983 - accuracy: 0.6730\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1580 - accuracy: 0.7186\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1709 - accuracy: 0.7795\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1936 - accuracy: 0.6958\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6011 - accuracy: 0.7567\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.4251 - accuracy: 0.7034\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3204 - accuracy: 0.7224\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3544 - accuracy: 0.7567\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9886 - accuracy: 0.6844\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5783 - accuracy: 0.6540\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.3228 - accuracy: 0.6350\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.4197 - accuracy: 0.7110\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 3.4410 - accuracy: 0.6844\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.5394 - accuracy: 0.6502\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.7315 - accuracy: 0.6958\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3369 - accuracy: 0.7072\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6479 - accuracy: 0.7072\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1728 - accuracy: 0.6578\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6091 - accuracy: 0.6920\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7122 - accuracy: 0.7072\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.1566 - accuracy: 0.75 - 0s 2ms/step - loss: 1.7671 - accuracy: 0.7300\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5198 - accuracy: 0.6730\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2724 - accuracy: 0.6996\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5743 - accuracy: 0.7605\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6969 - accuracy: 0.7414\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6016 - accuracy: 0.6578\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8205 - accuracy: 0.7376\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6926 - accuracy: 0.6768\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0386 - accuracy: 0.7224\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7799 - accuracy: 0.7072\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.4419 - accuracy: 0.7262\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3431 - accuracy: 0.6996\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3376 - accuracy: 0.6882\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5128 - accuracy: 0.7300\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5727 - accuracy: 0.7490\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4401 - accuracy: 0.6692\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3642 - accuracy: 0.7567\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2096 - accuracy: 0.6464\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0042 - accuracy: 0.7567\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1705 - accuracy: 0.6578\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.4223 - accuracy: 0.6882\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1847 - accuracy: 0.6616\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8857 - accuracy: 0.7110\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.9253 - accuracy: 0.6008\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5295 - accuracy: 0.6426\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3702 - accuracy: 0.6578\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4296 - accuracy: 0.6502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9102ad610>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(176, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(90, activation='relu'),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dense(70, activation='relu'),\n",
    "    tf.keras.layers.Dense(60, activation='relu'),\n",
    "    tf.keras.layers.Dense(21)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_c, y_train_c, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 7.9968 - accuracy: 0.0951 \n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3727 - accuracy: 0.4487\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.9996 - accuracy: 0.4829\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.7401 - accuracy: 0.4867\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.5692 - accuracy: 0.5209\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.4707 - accuracy: 0.6464\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3402 - accuracy: 0.6578\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.2739 - accuracy: 0.6616\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.1545 - accuracy: 0.7186\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0365 - accuracy: 0.7262\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.7452\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8899 - accuracy: 0.7567\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7930 - accuracy: 0.7833\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8683 - accuracy: 0.7643\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.8175\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.8327\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.8441\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.8479\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.8175\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.8175\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8327\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.8403\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8707\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8707\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8859\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.9011\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.9049\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9125\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9049\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.9316\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.9163\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9240\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.9202\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.9049\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.8973\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8897\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9316\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9468\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9506\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9506\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9734\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9658\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9734\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9848\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9810\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9848\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9848\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9696\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9430\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9506\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9810\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.9582\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9506\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9658\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9354\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9772\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9468\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9430\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9696\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9772\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9696\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9810\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9810\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9658\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9734\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9848\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9886\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9924\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9962\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9962\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.7835e-04 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.6668e-04 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.4069e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.3355e-04 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.1301e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.0838e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.7591e-04 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.5686e-04 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.6685e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.3496e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.4073e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.2390e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.7733e-04 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.3807e-04 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.4855e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7833e-04 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7092e-04 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.0868e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.9002e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.7538e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1418e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.9741e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.0161e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.8399e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4584e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.2516e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.3542e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.2923e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.9553e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.8579e-04 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.8036e-04 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.1669e-04 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8362e-04 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.4084e-04 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.3520e-04 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2712e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2114e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.1311e-04 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.0290e-04 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.9348e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8252e-04 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.7695e-04 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8167e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.6977e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4.6497e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5746e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5693e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4386e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5392e-04 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5224e-04 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4529e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3158e-04 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3357e-04 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1372e-04 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1362e-04 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0397e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0039e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9966e-04 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.0332e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9565e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8465e-04 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9973e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8281e-04 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7374e-04 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9193e-04 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.6425e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5698e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5735e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4781e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4082e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3945e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3347e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3386e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3502e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.2506e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3666e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1821e-04 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.2328e-04 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1275e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0974e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(176, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(90, activation='relu'),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dense(70, activation='relu'),\n",
    "    tf.keras.layers.Dense(60, activation='relu'),\n",
    "    tf.keras.layers.Dense(21)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train_w, y_train_w, epochs=200)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 2009.8451 - accuracy: 0.4753\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 642.1338 - accuracy: 0.4753\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 464.7596 - accuracy: 0.6160\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 245.5112 - accuracy: 0.5247\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 212.8921 - accuracy: 0.6388\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 166.1988 - accuracy: 0.5475\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 119.9935 - accuracy: 0.6198\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 89.2880 - accuracy: 0.6160\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 86.1002 - accuracy: 0.6160\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 135.7394 - accuracy: 0.6502\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 106.2578 - accuracy: 0.6388\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 92.9452 - accuracy: 0.6350\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 61.0843 - accuracy: 0.6350\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 53.3531 - accuracy: 0.5970\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 44.4329 - accuracy: 0.625 - 0s 5ms/step - loss: 62.1080 - accuracy: 0.6502\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 57.1770 - accuracy: 0.6350\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 51.3464 - accuracy: 0.6236\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 46.8151 - accuracy: 0.6046\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 41.6356 - accuracy: 0.6046\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 36.7481 - accuracy: 0.6008\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 37.2937 - accuracy: 0.6920\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.5032 - accuracy: 0.5894\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 77.4626 - accuracy: 0.6274\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 51.1392 - accuracy: 0.6616\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 41.5627 - accuracy: 0.5589\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 30.0253 - accuracy: 0.6616\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27.8953 - accuracy: 0.5856\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35.8375 - accuracy: 0.6692\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 19.8361 - accuracy: 0.6236\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 37.2441 - accuracy: 0.6388\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 37.9052 - accuracy: 0.6768\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35.4586 - accuracy: 0.6730\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 45.7202 - accuracy: 0.468 - 0s 5ms/step - loss: 27.0619 - accuracy: 0.6350\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 24.3763 - accuracy: 0.5894\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 24.0755 - accuracy: 0.6768\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.8875 - accuracy: 0.5817\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.3942 - accuracy: 0.6806\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 29.3359 - accuracy: 0.6578\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.2399 - accuracy: 0.6654\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.1971 - accuracy: 0.6426\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.4906 - accuracy: 0.6844\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 22.7293 - accuracy: 0.6996\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 18.1941 - accuracy: 0.6540\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 12.9117 - accuracy: 0.6654\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.5406 - accuracy: 0.5970\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 16.5594 - accuracy: 0.6806\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.9465 - accuracy: 0.6274\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.6089 - accuracy: 0.6274\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 14.2248 - accuracy: 0.5741\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 20.3177 - accuracy: 0.6464\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27.6441 - accuracy: 0.5817\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.5081 - accuracy: 0.6464\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 20.0915 - accuracy: 0.5589\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 20.8733 - accuracy: 0.6806\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 20.3900 - accuracy: 0.6350\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.1588 - accuracy: 0.5513\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 24.8836 - accuracy: 0.6160\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.2518 - accuracy: 0.6008\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.8435 - accuracy: 0.6882\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 14.1167 - accuracy: 0.6502\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.2466 - accuracy: 0.6350\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.3633 - accuracy: 0.6464\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.5352 - accuracy: 0.7224\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.8934 - accuracy: 0.6692\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 11.9607 - accuracy: 0.6730\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10.1487 - accuracy: 0.6540\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.5332 - accuracy: 0.6160\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17.1316 - accuracy: 0.6312\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 18.3118 - accuracy: 0.6122\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 15.3705 - accuracy: 0.6502\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 4.9332 - accuracy: 0.81 - 0s 4ms/step - loss: 13.9433 - accuracy: 0.6844\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 27.8143 - accuracy: 0.6274\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 20.2114 - accuracy: 0.6312\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 15.1071 - accuracy: 0.5703\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 14.7781 - accuracy: 0.6844\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.4224 - accuracy: 0.5589\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 20.1495 - accuracy: 0.6882\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 19.4711 - accuracy: 0.6844\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.9871 - accuracy: 0.6236\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.2855 - accuracy: 0.6730\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10.6122 - accuracy: 0.6654\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 9.3472 - accuracy: 0.6198\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 10.7958 - accuracy: 0.6768\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 8.0447 - accuracy: 0.6578\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.7561 - accuracy: 0.6236\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.0111 - accuracy: 0.6730\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.9513 - accuracy: 0.6350\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.1736 - accuracy: 0.6616\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.8409 - accuracy: 0.6464\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5584 - accuracy: 0.6768\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8248 - accuracy: 0.6008\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.6732 - accuracy: 0.6502\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.6031 - accuracy: 0.6616\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.1310 - accuracy: 0.6768\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1195 - accuracy: 0.6768\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.1622 - accuracy: 0.6958\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.5095 - accuracy: 0.7110\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4425 - accuracy: 0.6616\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0907 - accuracy: 0.7148\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2484 - accuracy: 0.6426\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0046 - accuracy: 0.6578\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1489 - accuracy: 0.6198\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.9409 - accuracy: 0.6616\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.0726 - accuracy: 0.6920\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1914 - accuracy: 0.6312\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.4855 - accuracy: 0.7224\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1737 - accuracy: 0.6692\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3823 - accuracy: 0.6616\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1166 - accuracy: 0.6844\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5159 - accuracy: 0.5057\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.6923 - accuracy: 0.6236\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1551 - accuracy: 0.6654\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 10.9379 - accuracy: 0.7148\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.8903 - accuracy: 0.5475\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 14.4219 - accuracy: 0.6274\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.2481 - accuracy: 0.6730\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 15.5510 - accuracy: 0.6008\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 13.0387 - accuracy: 0.6502\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10.4966 - accuracy: 0.5932\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.9741 - accuracy: 0.6046\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.6476 - accuracy: 0.7224\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.3532 - accuracy: 0.6996\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.7116 - accuracy: 0.6920\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1573 - accuracy: 0.6920\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3703 - accuracy: 0.6730\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.1310 - accuracy: 0.5589\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 15.4430 - accuracy: 0.7338\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.1479 - accuracy: 0.5894\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.6450 - accuracy: 0.7034\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1956 - accuracy: 0.7414\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.4837 - accuracy: 0.6958\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 12.6199 - accuracy: 0.3954\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 15.7643 - accuracy: 0.6008\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 15.7991 - accuracy: 0.6844\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.7232 - accuracy: 0.6616\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.4184 - accuracy: 0.6350\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.8278 - accuracy: 0.6008\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.7293 - accuracy: 0.6692\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 12.4551 - accuracy: 0.7148\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.5084 - accuracy: 0.6730\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.7951 - accuracy: 0.6654\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.9522 - accuracy: 0.6312\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.7942 - accuracy: 0.6768\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.3679 - accuracy: 0.6008\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8735 - accuracy: 0.6806\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.4920 - accuracy: 0.6312\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1508 - accuracy: 0.6920\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2894 - accuracy: 0.6882\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.1099 - accuracy: 0.6730\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.9248 - accuracy: 0.6388\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.4148 - accuracy: 0.6844\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.0378 - accuracy: 0.6844\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.2205 - accuracy: 0.7110\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5104 - accuracy: 0.6388\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.8696 - accuracy: 0.6844\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5572 - accuracy: 0.6730\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3636 - accuracy: 0.6882\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6702 - accuracy: 0.6996\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.7316 - accuracy: 0.6768\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7809 - accuracy: 0.7300\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.8077 - accuracy: 0.6958\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.7846 - accuracy: 0.6578\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4044 - accuracy: 0.6654\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8424 - accuracy: 0.6768\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5698 - accuracy: 0.6882\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3820 - accuracy: 0.6654\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5646 - accuracy: 0.7262\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2211 - accuracy: 0.5209\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.9665 - accuracy: 0.6350\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.3482 - accuracy: 0.6730\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2953 - accuracy: 0.6958\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.8475 - accuracy: 0.6844\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1760 - accuracy: 0.6502\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3171 - accuracy: 0.7262\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0786 - accuracy: 0.6730\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8140 - accuracy: 0.7262\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0941 - accuracy: 0.5817\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8167 - accuracy: 0.5894\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7469 - accuracy: 0.6654\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.1845 - accuracy: 0.6958\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.6283 - accuracy: 0.7262\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9821 - accuracy: 0.6274\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8214 - accuracy: 0.6312\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2450 - accuracy: 0.7300\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5603 - accuracy: 0.6274\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4122 - accuracy: 0.7262\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0276 - accuracy: 0.6920\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5947 - accuracy: 0.7186\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8710 - accuracy: 0.6388\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8432 - accuracy: 0.6084\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0122 - accuracy: 0.7110\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.6540\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7227 - accuracy: 0.7338\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3922 - accuracy: 0.6920\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4134 - accuracy: 0.6996\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8395 - accuracy: 0.7034\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0215 - accuracy: 0.6768\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.2876 - accuracy: 0.7034\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5666 - accuracy: 0.7072\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.6875 - accuracy: 0.6806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9119b0880>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(176, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(90, activation='relu'),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dense(70, activation='relu'),\n",
    "    tf.keras.layers.Dense(60, activation='relu'),\n",
    "    tf.keras.layers.Dense(21)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_m, y_train_m, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
